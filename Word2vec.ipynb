{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['you', 'say', 'goodbye', 'and', 'i', 'hello', '.'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(C)\n",
    "df.columns = ['you', 'say', 'goodbye', 'and', 'i', 'hello', '.']\n",
    "df.index   = ['you', 'say', 'goodbye', 'and', 'i', 'hello', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>say</th>\n",
       "      <th>goodbye</th>\n",
       "      <th>and</th>\n",
       "      <th>i</th>\n",
       "      <th>hello</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodbye</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         you  say  goodbye  and  i  hello  .\n",
       "you        0    1        0    0  0      0  0\n",
       "say        1    0        1    0  1      1  0\n",
       "goodbye    0    1        0    1  0      0  0\n",
       "and        0    0        1    0  1      0  0\n",
       "i          0    1        0    1  0      0  0\n",
       "hello      0    1        0    0  0      0  1\n",
       ".          0    0        0    0  0      1  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067691154799"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "cos_similarity(c0, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    \n",
    "    # 1. 列出Query\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 2. 計算Cosine Similarity\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    # 3. 從cosine similarity 由高到低列出數值結果\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>say</th>\n",
       "      <th>goodbye</th>\n",
       "      <th>and</th>\n",
       "      <th>i</th>\n",
       "      <th>hello</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodbye</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.807355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              you       say   goodbye       and         i     hello         .\n",
       "you      0.000000  1.807355  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "say      1.807355  0.000000  0.807355  0.000000  0.807355  0.807355  0.000000\n",
       "goodbye  0.000000  0.807355  0.000000  1.807355  0.000000  0.000000  0.000000\n",
       "and      0.000000  0.000000  1.807355  0.000000  1.807355  0.000000  0.000000\n",
       "i        0.000000  0.807355  0.000000  1.807355  0.000000  0.000000  0.000000\n",
       "hello    0.000000  0.807355  0.000000  0.000000  0.000000  0.000000  2.807355\n",
       ".        0.000000  0.000000  0.000000  0.000000  0.000000  2.807355  0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = ppmi(C)\n",
    "df = pandas.DataFrame(W)\n",
    "df.columns = ['you', 'say', 'goodbye', 'and', 'i', 'hello', '.']\n",
    "df.index   = ['you', 'say', 'goodbye', 'and', 'i', 'hello', '.']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[0 1 0 0 0 0 0]\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "[ 3.409e-01  0.000e+00 -1.205e-01 -3.886e-16 -9.323e-01 -1.110e-16\n",
      " -2.426e-17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "# plot\n",
    "from matplotlib import pyplot as plt\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size_a):\n",
    "            for o in range(layer_size_b):\n",
    "                pass\n",
    "                #line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                #                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                #ax.add_artist(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.gca()\n",
    "ax.axis('off')\n",
    "draw_neural_net(ax, .1, .9, .1, .9, [7, 3])\n",
    "#fig.savefig('nn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.279 -0.246 -4.729  3.355 -3.002  0.301  1.122]]\n"
     ]
    }
   ],
   "source": [
    "# サンプルのコンテキストデータ\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]] [1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "contexts, target = create_contexts_target(corpus, 1)\n",
    "print(contexts, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, 1)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0]],\n",
       "\n",
       "       [[0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1]]], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "#from common.np import *  # import numpy as np\n",
    "#from common.config import GPU\n",
    "#from common.functions import softmax, cross_entropy_error\n",
    "\n",
    "\n",
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = softmax(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.y = None  # softmaxの出力\n",
    "        self.t = None  # 教師ラベル\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        # 教師ラベルがone-hotベクトルの場合、正解のインデックスに変換\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None  # sigmoidの出力\n",
    "        self.t = None  # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "        self.loss = cross_entropy_error(np.c_[1 - self.y, self.y], self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = (self.y - self.t) * dout / batch_size\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "    '''\n",
    "    http://arxiv.org/abs/1207.0580\n",
    "    '''\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.params, self.grads = [], []\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "\n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    '''\n",
    "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
    "    '''\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
    "            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(params, grads):\n",
    "    '''\n",
    "    パラメータ配列中の重複する重みをひとつに集約し、\n",
    "    その重みに対応する勾配を加算する\n",
    "    '''\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 重みを共有する場合\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 勾配の加算\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 転置行列として重みを共有する場合（weight tying）\n",
    "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
    "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg: break\n",
    "            if find_flg: break\n",
    "\n",
    "        if not find_flg: break\n",
    "\n",
    "    return params, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = []\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            # シャッフル\n",
    "            idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "                # 勾配を求め、パラメータを更新\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # 評価\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| epoch %d |  iter %d / %d | time %d[s] | loss %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.loss_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label='train')\n",
    "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = softmax(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 2 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 3 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 4 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 5 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 6 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 7 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 8 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 9 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
      "| epoch 10 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 11 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 12 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 13 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 14 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 15 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 16 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 17 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 18 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 19 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 20 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 21 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 22 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 23 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 24 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 25 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 26 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 27 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 28 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
      "| epoch 29 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 30 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 31 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 32 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 33 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 34 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 35 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 36 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
      "| epoch 37 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 38 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 39 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 40 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 41 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 42 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 43 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
      "| epoch 44 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 45 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 46 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 47 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 48 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 49 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
      "| epoch 50 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 51 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 52 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
      "| epoch 53 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 54 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 55 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 56 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 57 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 58 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
      "| epoch 59 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 60 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 61 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
      "| epoch 62 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
      "| epoch 63 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
      "| epoch 64 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
      "| epoch 65 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 66 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
      "| epoch 67 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 68 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
      "| epoch 69 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
      "| epoch 70 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
      "| epoch 71 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
      "| epoch 72 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
      "| epoch 73 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
      "| epoch 74 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
      "| epoch 75 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
      "| epoch 76 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
      "| epoch 77 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
      "| epoch 78 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
      "| epoch 79 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 80 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
      "| epoch 81 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 82 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 83 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
      "| epoch 84 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 85 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
      "| epoch 86 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
      "| epoch 87 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
      "| epoch 88 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
      "| epoch 89 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
      "| epoch 90 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
      "| epoch 91 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
      "| epoch 92 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 93 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 94 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
      "| epoch 95 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
      "| epoch 96 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
      "| epoch 97 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
      "| epoch 98 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
      "| epoch 99 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
      "| epoch 100 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
      "| epoch 101 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
      "| epoch 102 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
      "| epoch 103 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
      "| epoch 104 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 105 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 106 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 107 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 108 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 109 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 110 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
      "| epoch 111 |  iter 1 / 2 | time 0[s] | loss 1.69\n",
      "| epoch 112 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 113 |  iter 1 / 2 | time 0[s] | loss 1.67\n",
      "| epoch 114 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 115 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
      "| epoch 116 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
      "| epoch 117 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
      "| epoch 118 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
      "| epoch 119 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
      "| epoch 120 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
      "| epoch 121 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
      "| epoch 122 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
      "| epoch 123 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
      "| epoch 124 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 125 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
      "| epoch 126 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
      "| epoch 127 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
      "| epoch 128 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 129 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
      "| epoch 130 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
      "| epoch 131 |  iter 1 / 2 | time 0[s] | loss 1.59\n",
      "| epoch 132 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
      "| epoch 133 |  iter 1 / 2 | time 0[s] | loss 1.58\n",
      "| epoch 134 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
      "| epoch 135 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
      "| epoch 136 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
      "| epoch 137 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
      "| epoch 138 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
      "| epoch 139 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
      "| epoch 140 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
      "| epoch 141 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
      "| epoch 142 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
      "| epoch 143 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
      "| epoch 144 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
      "| epoch 145 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
      "| epoch 146 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
      "| epoch 147 |  iter 1 / 2 | time 0[s] | loss 1.49\n",
      "| epoch 148 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
      "| epoch 149 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
      "| epoch 150 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
      "| epoch 151 |  iter 1 / 2 | time 0[s] | loss 1.48\n",
      "| epoch 152 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
      "| epoch 153 |  iter 1 / 2 | time 0[s] | loss 1.49\n",
      "| epoch 154 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
      "| epoch 155 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
      "| epoch 156 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
      "| epoch 157 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
      "| epoch 158 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
      "| epoch 159 |  iter 1 / 2 | time 0[s] | loss 1.45\n",
      "| epoch 160 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
      "| epoch 161 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
      "| epoch 162 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
      "| epoch 163 |  iter 1 / 2 | time 0[s] | loss 1.44\n",
      "| epoch 164 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 165 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
      "| epoch 166 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 167 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
      "| epoch 168 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
      "| epoch 169 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 170 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 171 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 172 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 173 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
      "| epoch 174 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 175 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
      "| epoch 176 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 177 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 178 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
      "| epoch 179 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
      "| epoch 180 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 181 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
      "| epoch 182 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
      "| epoch 183 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 184 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 185 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 186 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
      "| epoch 187 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
      "| epoch 188 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
      "| epoch 189 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
      "| epoch 190 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
      "| epoch 191 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
      "| epoch 192 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
      "| epoch 193 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
      "| epoch 194 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 195 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 196 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
      "| epoch 197 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
      "| epoch 198 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
      "| epoch 199 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 200 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
      "| epoch 201 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
      "| epoch 202 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 203 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
      "| epoch 204 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 205 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
      "| epoch 206 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 207 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 208 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
      "| epoch 209 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
      "| epoch 210 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 211 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 212 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
      "| epoch 213 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 214 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 215 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 216 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 217 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 218 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 219 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 220 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
      "| epoch 221 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 222 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 223 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 224 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 225 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
      "| epoch 226 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 227 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 228 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 229 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 230 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 231 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
      "| epoch 232 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 233 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
      "| epoch 234 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 235 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
      "| epoch 236 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 237 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 238 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
      "| epoch 239 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 240 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
      "| epoch 241 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 242 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 243 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 244 |  iter 1 / 2 | time 0[s] | loss 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 245 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
      "| epoch 246 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 247 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
      "| epoch 248 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 249 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 250 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 251 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 252 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 253 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 254 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 255 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
      "| epoch 256 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
      "| epoch 257 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 258 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
      "| epoch 259 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 260 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
      "| epoch 261 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 262 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 263 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 264 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 265 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 266 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 267 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 268 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 269 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
      "| epoch 270 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 271 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 272 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
      "| epoch 273 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 274 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 275 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 276 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
      "| epoch 277 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 278 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 279 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 280 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 281 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
      "| epoch 282 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 283 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 284 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 285 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 286 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 287 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 288 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
      "| epoch 289 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 290 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
      "| epoch 291 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 292 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 293 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
      "| epoch 294 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 295 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 296 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 297 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 298 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 299 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
      "| epoch 300 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 301 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 302 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 303 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
      "| epoch 304 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 305 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 306 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
      "| epoch 307 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 308 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
      "| epoch 309 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 310 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
      "| epoch 311 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 312 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 313 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 314 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
      "| epoch 315 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 316 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 317 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 318 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
      "| epoch 319 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 320 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 321 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 322 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
      "| epoch 323 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 324 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 325 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
      "| epoch 326 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
      "| epoch 327 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 328 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 329 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 330 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 331 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 332 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 333 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 334 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 335 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 336 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 337 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 338 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 339 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
      "| epoch 340 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 341 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
      "| epoch 342 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 343 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 344 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 345 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 346 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 347 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 348 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 349 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 350 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 351 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 352 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 353 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 354 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
      "| epoch 355 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 356 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 357 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 358 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 359 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 360 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 361 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 362 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 363 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 364 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 365 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
      "| epoch 366 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 367 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 368 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 369 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
      "| epoch 370 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
      "| epoch 371 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 372 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 373 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 374 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 375 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 376 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 377 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 378 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 379 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 380 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 381 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
      "| epoch 382 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 383 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 384 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 385 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 386 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 387 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
      "| epoch 388 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 389 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 390 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 391 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 392 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
      "| epoch 393 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 394 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 395 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 396 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 397 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 398 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 399 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
      "| epoch 400 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 401 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
      "| epoch 402 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 403 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 404 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
      "| epoch 405 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 406 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 407 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 408 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 409 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 410 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 411 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 412 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 413 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 414 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 415 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 416 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
      "| epoch 417 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 418 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 419 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 420 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 421 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 422 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 423 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 424 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 425 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
      "| epoch 426 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 427 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 428 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 429 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 430 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 431 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 432 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 433 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 434 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 435 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 436 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 437 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 438 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 439 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 440 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 441 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 442 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 443 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 444 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 445 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 446 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
      "| epoch 447 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 448 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 449 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 450 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 451 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
      "| epoch 452 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 453 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 454 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 455 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 456 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 457 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
      "| epoch 458 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 459 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 460 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
      "| epoch 461 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 462 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 463 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 464 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 465 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 466 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 467 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 468 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
      "| epoch 469 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 470 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 471 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 472 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 473 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 474 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 475 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 476 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 477 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 478 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 479 |  iter 1 / 2 | time 0[s] | loss 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 480 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 481 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 482 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 483 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 484 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 485 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 486 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
      "| epoch 487 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 488 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 489 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 490 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 491 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
      "| epoch 492 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 493 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 494 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 495 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 496 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 497 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 498 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 499 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 500 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 501 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 502 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 503 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 504 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 505 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 506 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 507 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
      "| epoch 508 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 509 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 510 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 511 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 512 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
      "| epoch 513 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 514 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 515 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 516 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 517 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 518 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 519 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 520 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 521 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 522 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 523 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 524 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 525 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 526 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 527 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 528 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 529 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 530 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 531 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 532 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 533 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 534 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 535 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 536 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 537 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 538 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 539 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
      "| epoch 540 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 541 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 542 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 543 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 544 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 545 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 546 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 547 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 548 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 549 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 550 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 551 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 552 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 553 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 554 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 555 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 556 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 557 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
      "| epoch 558 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 559 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 560 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
      "| epoch 561 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 562 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 563 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 564 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 565 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 566 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 567 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 568 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 569 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
      "| epoch 570 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 571 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 572 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 573 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 574 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 575 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 576 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 577 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 578 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 579 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 580 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 581 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 582 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 583 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 584 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
      "| epoch 585 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 586 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 587 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 588 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 589 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 590 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 591 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 592 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 593 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 594 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 595 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 596 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 597 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 598 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 599 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 600 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 601 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 602 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 603 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 604 |  iter 1 / 2 | time 0[s] | loss 0.26\n",
      "| epoch 605 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 606 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 607 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 608 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 609 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 610 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 611 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 612 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 613 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 614 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 615 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 616 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 617 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 618 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 619 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 620 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 621 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 622 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 623 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 624 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
      "| epoch 625 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 626 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 627 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 628 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 629 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 630 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 631 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 632 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 633 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 634 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 635 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
      "| epoch 636 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 637 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 638 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 639 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 640 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 641 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 642 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 643 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 644 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 645 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 646 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 647 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 648 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 649 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 650 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
      "| epoch 651 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 652 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 653 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 654 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 655 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
      "| epoch 656 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 657 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 658 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 659 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
      "| epoch 660 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 661 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 662 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 663 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 664 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 665 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 666 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 667 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 668 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 669 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 670 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 671 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 672 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 673 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 674 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 675 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 676 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
      "| epoch 677 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 678 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 679 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
      "| epoch 680 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 681 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 682 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 683 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 684 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 685 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 686 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 687 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 688 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 689 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 690 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
      "| epoch 691 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
      "| epoch 692 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 693 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 694 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 695 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 696 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 697 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 698 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 699 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 700 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 701 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 702 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
      "| epoch 703 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 704 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 705 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 706 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 707 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 708 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 709 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 710 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 711 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 712 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 713 |  iter 1 / 2 | time 0[s] | loss 0.27\n",
      "| epoch 714 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 715 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 716 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
      "| epoch 717 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
      "| epoch 718 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 719 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 720 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 721 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 722 |  iter 1 / 2 | time 0[s] | loss 0.27\n",
      "| epoch 723 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 724 |  iter 1 / 2 | time 0[s] | loss 0.27\n",
      "| epoch 725 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 726 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
      "| epoch 727 |  iter 1 / 2 | time 0[s] | loss 0.16\n",
      "| epoch 728 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
      "| epoch 729 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 730 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 731 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 732 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 733 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 734 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 735 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 736 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 737 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
      "| epoch 738 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 739 |  iter 1 / 2 | time 0[s] | loss 0.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 740 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 741 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
      "| epoch 742 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 743 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
      "| epoch 744 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 745 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 746 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 747 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
      "| epoch 748 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 749 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 750 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 751 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 752 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 753 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 754 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 755 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 756 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
      "| epoch 757 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 758 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 759 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
      "| epoch 760 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 761 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 762 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
      "| epoch 763 |  iter 1 / 2 | time 0[s] | loss 0.27\n",
      "| epoch 764 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
      "| epoch 765 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 766 |  iter 1 / 2 | time 0[s] | loss 0.26\n",
      "| epoch 767 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 768 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 769 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 770 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 771 |  iter 1 / 2 | time 0[s] | loss 0.26\n",
      "| epoch 772 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 773 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 774 |  iter 1 / 2 | time 0[s] | loss 0.26\n",
      "| epoch 775 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 776 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 777 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 778 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
      "| epoch 779 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 780 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 781 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 782 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 783 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 784 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 785 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 786 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 787 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 788 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 789 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 790 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 791 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 792 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 793 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 794 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 795 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 796 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 797 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 798 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 799 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 800 |  iter 1 / 2 | time 0[s] | loss 0.25\n",
      "| epoch 801 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 802 |  iter 1 / 2 | time 0[s] | loss 0.13\n",
      "| epoch 803 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 804 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 805 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 806 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 807 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 808 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 809 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 810 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 811 |  iter 1 / 2 | time 0[s] | loss 0.11\n",
      "| epoch 812 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
      "| epoch 813 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 814 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 815 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
      "| epoch 816 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 817 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 818 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 819 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 820 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 821 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 822 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 823 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 824 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
      "| epoch 825 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 826 |  iter 1 / 2 | time 0[s] | loss 0.12\n",
      "| epoch 827 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 828 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 829 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 830 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 831 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
      "| epoch 832 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 833 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 834 |  iter 1 / 2 | time 0[s] | loss 0.13\n",
      "| epoch 835 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 836 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 837 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 838 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 839 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 840 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 841 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 842 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 843 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 844 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 845 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 846 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
      "| epoch 847 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 848 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
      "| epoch 849 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 850 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 851 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 852 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 853 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 854 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 855 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 856 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 857 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 858 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 859 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
      "| epoch 860 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 861 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 862 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 863 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
      "| epoch 864 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 865 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
      "| epoch 866 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 867 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 868 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 869 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 870 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 871 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 872 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 873 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 874 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
      "| epoch 875 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 876 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
      "| epoch 877 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 878 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 879 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 880 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 881 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 882 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 883 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 884 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 885 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 886 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 887 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 888 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 889 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 890 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
      "| epoch 891 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 892 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 893 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 894 |  iter 1 / 2 | time 0[s] | loss 0.11\n",
      "| epoch 895 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
      "| epoch 896 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 897 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 898 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 899 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 900 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 901 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 902 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 903 |  iter 1 / 2 | time 0[s] | loss 0.22\n",
      "| epoch 904 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 905 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 906 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 907 |  iter 1 / 2 | time 0[s] | loss 0.21\n",
      "| epoch 908 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 909 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 910 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 911 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 912 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 913 |  iter 1 / 2 | time 0[s] | loss 0.09\n",
      "| epoch 914 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 915 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 916 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 917 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 918 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 919 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
      "| epoch 920 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 921 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 922 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 923 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 924 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 925 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 926 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 927 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 928 |  iter 1 / 2 | time 0[s] | loss 0.18\n",
      "| epoch 929 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 930 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 931 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 932 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 933 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 934 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 935 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 936 |  iter 1 / 2 | time 0[s] | loss 0.09\n",
      "| epoch 937 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 938 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 939 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 940 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 941 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 942 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 943 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 944 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 945 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 946 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 947 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 948 |  iter 1 / 2 | time 0[s] | loss 0.09\n",
      "| epoch 949 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 950 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 951 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 952 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 953 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 954 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 955 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 956 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 957 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 958 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
      "| epoch 959 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 960 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
      "| epoch 961 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 962 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 963 |  iter 1 / 2 | time 0[s] | loss 0.18\n",
      "| epoch 964 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
      "| epoch 965 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 966 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
      "| epoch 967 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 968 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 969 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 970 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 971 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 972 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 973 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 974 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 975 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 976 |  iter 1 / 2 | time 0[s] | loss 0.07\n",
      "| epoch 977 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 978 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 979 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 980 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 981 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 982 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 983 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
      "| epoch 984 |  iter 1 / 2 | time 0[s] | loss 0.08\n",
      "| epoch 985 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 986 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 987 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
      "| epoch 988 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
      "| epoch 989 |  iter 1 / 2 | time 0[s] | loss 0.18\n",
      "| epoch 990 |  iter 1 / 2 | time 0[s] | loss 0.18\n",
      "| epoch 991 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 992 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
      "| epoch 993 |  iter 1 / 2 | time 0[s] | loss 0.19\n",
      "| epoch 994 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
      "| epoch 995 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 996 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 997 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 998 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 999 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
      "| epoch 1000 |  iter 1 / 2 | time 0[s] | loss 0.41\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XeYVNX5wPHvu42lLH3pZUGaINJWEMWOCGrEGI1gbzEajS3xF4yxRKPBmJhorFhj72IBQayggLL0DguiNGFpSxW2vL8/7p3Z2dmZ3dnduTO7s+/neeZx7rllzjDrvHPuOec9oqoYY4wxFUmKdwWMMcbUDhYwjDHGRMQChjHGmIhYwDDGGBMRCxjGGGMiYgHDGGNMRCxgGGOMiYgFDGOMMRGxgGGMMSYiKfGuQDS1bNlSs7Ky4l0NY4ypNebOnbtNVTMjOdazgCEiHYEXgdaAAhNU9eGgYwR4GDgd2A9cpqrz3H2XAn9xD/2bqv6votfMysoiJycnem/CGGMSnIj8EOmxXrYwCoE/qOo8EckA5orINFVdFnDMKKC7+xgCPAEMEZHmwF1ANk6wmSsiH6jqTg/ra4wxphye9WGo6mZfa0FV9wDLgfZBh40GXlTHbKCpiLQFTgOmqeoON0hMA0Z6VVdjjDEVi0mnt4hkAQOAb4N2tQfWB2xvcMvClRtjjIkTzwOGiDQC3gFuUtXdHlz/ahHJEZGcvLy8aF/eGGOMy9OAISKpOMHiFVV9N8QhG4GOAdsd3LJw5WWo6gRVzVbV7MzMiDr6jTHGVIFnAcMdAfUssFxVHwpz2AfAJeI4GshX1c3AVGCEiDQTkWbACLfMGGNMnHg5SupY4GJgsYgscMv+DHQCUNUngck4Q2pzcYbVXu7u2yEi9wJz3PPuUdUdHtbVGGNMBTwLGKr6NSAVHKPAdWH2PQc850HVynjks9UkCaSnJlM/LZmWjerRvml9OrdoQEZ6aiyqYIwxNV5CzfSuqie/WsP+Q0VlykXgsMxGDOzUlBN7tuKUw1tRLyU5DjU0xpj4E+dHfmLIzs7Wqs70PlRYzIGCIg4cKiJvz0E27NzP6q17Wbh+F1/nbuNgYTFNG6Ry/lEduXJYF1plpEe59sYYE3siMldVsyM61gJGxX4uKGLasi28NOsHvlu3g+Qk4eKjO/Onkb2on2YtDmNM7WUBw0ML1+/i8hfmsGPfIZo2SOW2Ub34dXZHnEFhxhhTu1QmYFh680rq17Eps287hXGjerFrfwF/emcxN72xgMKi4nhXzRhjPGUBowrSUpK45oTDmHP7cBqnp/D+gk388vGZLFy/K95VM8YYz1jAqIbMjHosuvs0fnNcFxZvzGf0Y98we+32eFfLGGM8YQEjCm4/ozfHHNYCgDETZrN+x/4418gYY6LPAkaUvHTlEG44uRsAx/3jCxZvyI9zjYwxJrosYERJcpJwy4ie/Of8/gD84tGvyd26J861MsaY6LGAEWVnHNmWQZ2bATD8oelMnB8yya4xxtQ6FjCiLDU5iXeuPYYj2jcG4KY3FvD9tn1xrpUxxlSfBQyPTPzdsf7nJ/3zy/hVxBhjosQChkdSkpNYdPcI//a4dxax/1BhHGtkjDHVYwHDQ43TU/nu9lMAeH3Oem58fQHFxYmTisUYU7dYwPBYq4x0Jlw8CIBpy7bw6Be5ca6RMcZUjQWMGBjRpw3DD28FwEPTVrFp14E418gYYyrPyzW9nxORrSKyJMz+W0VkgftYIiJFItLc3bdORBa7+7xNPxsj9559hP/5hOlr41gTY4ypGi9bGC8AI8PtVNUHVbW/qvYHbgO+Clq3+yR3f0Rpd2u6tk3qs/b+0+nVJoMXZq7jqa/WxLtKxhhTKZ4FDFWdDuyo8EDHWOA1r+pSUyQlCcO6tQRg/JQVHAixLKwxxtRUce/DEJEGOC2RdwKKFfhEROaKyNXxqZk3/nhaT/5+Tl9U4fA7pzBzzbZ4V8kYYyIS94AB/AL4Juh21DBVHQiMAq4TkePDnSwiV4tIjojk5OXleV3XaktPTeaXA9r7t3/3yrw41sYYYyJXEwLGGIJuR6nqRve/W4H3gMHhTlbVCaqararZmZmZnlY0WtJTk8m9bxQAu/YXWCvDGFMrxDVgiEgT4ATg/YCyhiKS4XsOjABCjrSqzVKSk/z9GRc8/W2ca2OMMRXzcljta8AsoKeIbBCRK0XkGhG5JuCwXwKfqGpgdr7WwNcishD4DpikqlO8qmc8PeVO6AN4YMoKtu89GMfaGGNM+UQ1cVJVZGdna05O7Zq2ccfEJbw0+wf/9rrxZ8SxNsaYukZE5kY6faEm9GHUaXf9ojf/Pr9fvKthjDEVsoARZynJSQzq1Ny//Yv/fs2avL1xrJExxoRmAaMG6NCsPsd2awHA4o35nPKvr1iwfleca2WMMaVZwKgBkpKEl68cUqps6+6f41QbY4wJzQJGDSEiXH18V/92QVHiDEYwxiQGCxg1yHUndqNbq0bO81fnccHTs+NcI2OMKWEBowZp0iCVj34/zL89c832ONbGGGNKs4BRw6SnJnPZMVn+7fwDBfGrjDHGBLCAUQPdfVYf//N+f/2Ehz5ZGcfaGGOMwwJGDdWnXWP/80c+t3XAjTHxZwGjhnriwkGltu3WlDEm3ixg1FCdWjRgxb0jue+XzlrgHy7cFOcaGWPqOgsYNVh6ajL9OzYF4C8Tl5BIiSKNMbWPBYwarnOLhv7nXW6bzJx1kS6Tbowx0WUBo4ZrVC+FXm0y/Nufr9gax9oYY+oyCxi1wDOXZnNyr1YAPPHlGt5fsDHONTLG1EUWMGqBDs0a8NxlR/m3b3x9QRxrY4ypqyxg1FJjJsxi78HCeFfDGFOHeLmm93MislVEloTZf6KI5IvIAvdxZ8C+kSKyUkRyRWScV3WsbVKSxP989tod3PX+0jjWxhhT13jZwngBGFnBMTNUtb/7uAdARJKBx4BRQG9grIj09rCetca0W06gecM0//bSTfkUFSsL1u+ioKg4jjUzxtQFngUMVZ0OVGUM6GAgV1XXquoh4HVgdFQrV0t1admQKTcd599e8dMeDvvzZM5+7Bse+HhFHGtmjKkL4t2HMVREForIxyLiy7jXHlgfcMwGtywkEblaRHJEJCcvL8/LutYIrTLSqZ+aXKZ80Yb8ONTGGFOXxDNgzAM6q2o/4L/AxKpcRFUnqGq2qmZnZmZGtYI1VeDKfD5FNgvcGOOxuAUMVd2tqnvd55OBVBFpCWwEOgYc2sEtM66bhncvU1ZUrHyxYqutBW6M8UzcAoaItBERcZ8PduuyHZgDdBeRLiKSBowBPohXPWsiEeEUdyKfz4L1u7j8hTn8+qlZcaqVMSbRpXh1YRF5DTgRaCkiG4C7gFQAVX0SOBe4VkQKgQPAGHWy6xWKyPXAVCAZeE5VbfxokMcuHMjuAwUMvv+zUuXrtu+PU42MMYnOs4ChqmMr2P8o8GiYfZOByV7UK1Gkpya7jyR+LrAhtcYY78V7lJSppoZpnsV8Y4wpxQJGLffrozqWKZv/48441MQYk+gsYNRyt47oWaZs4nwbVGaMiT4LGLVcUpLwfEAmW4Dt+w5RUFTM/B932oJLxpiosRvgCeCkXq04Z2B73p3ntCw+WrSZjxZt9u+f+5fhtGhUL17VM8YkCGthJIjUpPAf5aC/fRrDmhhjEpUFjARx1XFdALj+pG4h9/f76yc8/833saySMSbBWMBIEN1bZ7Bu/Bn88bSyneAA+QcK+OuHy2JcK2NMIrGAYYwxJiIWMBLQ/64YHHbf7LXbY1gTY0wisYCRgE7oET7N+5gJs7nyhTkALNmYT+7WvbGqljGmlrNhtXXQZyu2AnDmf78GYN34M+JZHWNMLWEtjAR17qAO8a6CMSbBWMBIUP88rx+/zg4fNLbusYWWjDGVYwEjgaUkh/94X579YwxrYoxJBBYwEtifRvbimUuy6d6qUZl9qUkShxoZY2ozCxgJrEn9VIb3bs3xIUZNldf6MMaYUDz71hCR50Rkq4gsCbP/QhFZJCKLRWSmiPQL2LfOLV8gIjle1bGuGDeqV5myB6asiENNjDG1mZc/M18ARpaz/3vgBFXtC9wLTAjaf5Kq9lfVbI/qV2ekWmvCGBMFXq7pPV1EssrZPzNgczZg40CNMaYGqyk/Pa8EPg7YVuATEZkrIleXd6KIXC0iOSKSk5eX52kla7PBWc3D7tuy24bYGmMqFveAISIn4QSMPwUUD1PVgcAo4DoROT7c+ao6QVWzVTU7MzN8Soy67s1rhvKv8/qF3HfcA1/EuDbGmNoorgFDRI4EngFGq6o/K56qbnT/uxV4DwifTc9ELNwaS4eKihn698+spWGMKVfcAoaIdALeBS5W1VUB5Q1FJMP3HBgBhBxpZSonScLPvdic/zND7v+MrHGTmP/jTgC+XLmV1Vv2xKp6xpgazrNObxF5DTgRaCkiG4C7gFQAVX0SuBNoATwuzhdZoTsiqjXwnluWAryqqlO8qmddUl7ACPSPKSvp064xz3ztrNAXmJxw0YZdZLVsSOP0VE/qaIypubwcJTW2gv1XAVeFKF8LhL7Zbqol2Z3dPbJPG/46ug9D7v8s5HGz1m5nVoh1M4qKlbMe/Yajsprx1jXHeFpXY0zNE/dObxM7h7dtDMBpR7SmdeN0bhrePaLzFq7fxcL1uygsLgZg/o+7PKujMabmsoBRh3Rp2ZCVfxvJLwc4U15uGt6DFfeWN7fSMfqxbxj92DfkHyjwuorGmBrMAkYdUy8ludR2emoyx3ZrEdG5g+8LfQvLGFM3WMAwqEbnOtv3HuTZr79Ho3VBY0yNYku0mqi55c2FfLUqj+Wbd3PP6D40SLM/L2MSif0fbSrdwgg3OneX28fx9twNFBYV8+czDqdVRno1a2eMqSnslpThuB4tK3V82AATsGPigk3W52FMgrGAYbjm+MOYOe7kSp2zfPNu3pu/waMaGWNqIrslZUhKEto1rV+pc0Y9PAPAP0TXGJP4rIVhKi3wjtTyzbv5uaAobnUxxsSOBQxTaUXFJSFj1MMzuPmNBUDpQBLsfzPXkbt1r8c1M8Z4yQKG8TuxZ9XWE/l4yU+c8GD4NTVUlbs+WMroR7+uatWMMTWA9WEYv6cuHsS+g0Ws2LybxRvz+fvHKyI+94ft+8PuK3RbJPsO2a0rY2qziFoYInKjiDQWx7MiMk9ERnhdORNb9VKSad4wjWO6taRZg7SoXbewyGZ+G5MIIr0ldYWq7sZZzKgZcDEw3rNambgb3rt11K5V4Ga5DTfhb+vun/nXJyspLrbAYkxNFmnA8P2vfjrwkqouDSgzCah5w+i1MIrcFka4P5g/vr2I/36eyzx3pT9jTM0UacCYKyKf4ASMqe4SqsXeVcskkhdmrgPCr/jnG5ZrDQxjarZIA8aVwDjgKFXdj7PU6uUVnSQiz4nIVhEJuSa32yfyiIjkisgiERkYsO9SEVntPi6NsJ6mBnr4s9VA+FtS5Y7HNcbUGJEGjKHASlXdJSIXAX8B8iM47wWgvBV6RgHd3cfVwBMAItIcZw3wIcBg4C4RaRZhXU0N8ogbLACkgjXFI1xy3BgTJ5EGjCeA/SLSD/gDsAZ4saKTVHU6sKOcQ0YDL6pjNtBURNoCpwHTVHWHqu4EplF+4DEea9ekbNbZJvVTKzzvoWmr/M8PFRZz3Svzws4Mt2U0jKnZIg0YheqsijMaeFRVHwMyovD67YH1Adsb3LJw5SaGgify9WydwXUnHebf9gWMTs0bRHzNSYs30+uOKby/YGN0KmmMiZlIA8YeEbkNZzjtJBFJwunHiDsRuVpEckQkJy8vL97VSSjPXJLN5384AXC6GabefDy3ntaLU90ht76AccrhrSp97RtfX8BjX+SWKrNbUsbUbJEGjPOBgzjzMX4COgAPRuH1NwIdA7Y7uGXhystQ1Qmqmq2q2ZmZVUttYUJLSU6ifpqzBni9lJI/lUfGDODzP5zg31fVW0kPTl3JY1/kotbrbUytEFHAcIPEK0ATETkT+FlVK+zDiMAHwCXuaKmjgXxV3QxMBUaISDO3s3uEW2ZirE3jdG48pTsvXD7YX1Y/LZmumY1IS3b+fPYdLKzy9R+cupI562z+hTG1QaSpQX4NfAecB/wa+FZEzo3gvNeAWUBPEdkgIleKyDUico17yGRgLZALPA38DkBVdwD3AnPcxz1umYkxEeHmU3uQ1bJhmX0XDOkEQOcWkfdhlGf1lr2lMuEaY2oW0QjuJ4jIQuBUVd3qbmcCn6pqP4/rVynZ2dmak5MT72rUOa98+wO3vxdyqk2VPDymP6P72xgHY2JBROaqanYkx0bah5HkCxau7ZU41yS4aA+HvfH1BcxYXb0BDLlb9zBmwiz2H6r67TJjTGmRfulPEZGpInKZiFwGTMK5nWQM5w6K/jKtFz/7HTNW5zFn3Q627z1Y6fPv/Wg5s9fu4Nu1difTmGiJaD0MVb1VRH4FHOsWTVDV97yrlqlN0lOTWXv/6XT9c3R/Q1z87Hf+5+vGn1Gpc31DdG0EljHRE/FtJVV9R1VvcR8WLEwpSUnCq1cN8ez6q7fsqdTxvikdHy3azOy126NfIWPqoHIDhojsEZHdIR57RGR3rCppaofDWjXy7Npb91T+thTAu/M2MmbC7CjXxpi6qdyAoaoZqto4xCNDVRvHqpKmdmiVUY8bTunuybVVYfqqPNbv2M+hwmK27vkZgIXrd7Fow64yx1eU6DDYzDXbmPuD9XcYUx5b09tEjYhwy6k96NaqETe8Nj+q11aUS577rlTZ2vtPZ/Rj3wBl+zgqm2Xkgqe/DXkdY0wJGxprou6sfu244eRuUb1mqKG7hQGT/A4Wls6Aa3mpjIk+CxjGEzec0p23rhnK76MUOELNAC8oKln0sedfpgTttYhhTLRZwDCeSElO4qis5vxhRM+oXO9gYdkVgQMDhtfezFnPzDXbYvZ6xtREFjBMrRBq0aUDQWXzf3SSGD7y2Wo+W7Elqq//f28v8vdzGFNXWcAwMfPkRYOqfO6+ECk+8g8UlNr+5eMzKS5WHpq2ylbvM8YDFjBMzAyvwkJLPvsPlm1h7D9UtmxT/oEqv4YxpnwWMEzMJCcJL14xuOIDQ7hv8vIyZQdCBIxd+wvKlAEUFyt3f7CUp6evjWnfhzGJxAKGiRkR4fgemUy87tiKD45AqBZGYZj1NFb8tIcXZq7jvsnLefjT1VF5fWPqGgsYJub6d2walQlyv3mx7NonRcWhWw9v5qz3P1+3fR9Z4ybx4qx1ZY679a2FnPDgF/7tfQcL+XDhpmrX1ZhEYAHDJJTCotAtjBdmrvM/97VM/hOipfHW3A38sH2/f/vP7y3m91GetW5MbeVpwBCRkSKyUkRyRWRciP3/FpEF7mOViOwK2FcUsO8DL+tp4uuJCwdG7Vo79x+q8JjkJGdSXySrTW7cWboTXVV57Itc8qqYDNGY2syzgCEiycBjwCigNzBWRHoHHqOqN6tqf1XtD/wXeDdg9wHfPlU9y6t6mvgb3KU5XUOsGV4V17w8r8Jj3HhBJMuHFwcFlQXrd/Hg1JXc8uaCUuUHC4v4cOGmiIKQMbWVly2MwUCuqq5V1UPA68Doco4fC7zmYX1MnLxz7VD+fk7fsPvrpSbz+R9PjF2FXPkHChj96NeVOseXoiS4w/2hT1bx+9fm89WqPHb/HHqkljG1nZcBoz2wPmB7g1tWhoh0BroAnwcUp4tIjojMFpGzvaum8dqgzs0ZO7hT2P3JVcwUmJJUtfMCGwELN+SXuzhTpO2FzflOuvVvcrdx5N2fWEe5SUg1pdN7DPC2qgb+bOusqtnABcB/ROSwUCeKyNVuYMnJy8uLRV1NlCUF/RUuvGsEH/1+GI3qlZ99v3vrjKi8/qn/nh52X/Btqz0Hy844D7R4Yz4AX6928k79+b3FZI2bBDjzRkKlODGmtvAyYGwEOgZsd3DLQhlD0O0oVd3o/nct8CUwINSJqjpBVbNVNTszM7O6dTZxENzCSE0WjmjfhP+ODfmR+1W5hRHhcYs27GLh+tKLM13+/Jxyz/EFGF8QfPXbH/37Dr9zCseO/zzEWcbUDl4GjDlAdxHpIiJpOEGhzGgnEekFNANmBZQ1E5F67vOWwLHAMg/rauIoOeiL37d9Uq9WrPzbSMYc1THUaWXOi6ascZM469Fvwu5fk7eXrHGT/PM7fDGv2I0Y4Vb8276v4lFcxtRUngUMVS0ErgemAsuBN1V1qYjcIyKBo57GAK9r6eElhwM5IrIQ+AIYr6oWMBJMF3dkVPCXa0rAPap6KcmM/9WRTLnpuFLH3HhK9yoHjGgMZPKlIPm/txcBJatvFLkXD66a16Onvl27naxxk/xL1xrjBU+XaFXVycDkoLI7g7bvDnHeTCD8sBqTEN747dGs/Klsh3OoONCrTWPWjT/D3x9w86k9mLVme5Ve99Pl0U19DiVBz3dLSoIWcIpkCG91PPfN9wDMXbeTUX3bevtips6qKZ3epg5qlZHOcd3L9juFu50TzMtbUlXla0m8NPsHPl1WEphCrRhYGX/9cKk/WJbHlqY1XvK0hWFMtC2481T/l+9FR3dm1tqqtTK8EjjR76qAXFfBEwAr6/lv1lXrfGOiwVoYpsb4Rb92FR7TtEEaLRrVA+CMI9vStkm619WKiL8PI0zm9MAWRqEH6dWr20Xy9PS1pRI0GhOKBQxTYzx8fn9W/W1Upc7p1aZkLkZLN5DERdAoqWCBade73f4xSzbmV2mN8A0791dwRNXuSd03ebm/A9+YcCxgmBojKUlIS6ncn+QjYwfwp5G9AHjo1/28qFaFssZN4t15zhSjcLeeggPJmf/9mgue/pZd+w/xw/Z9rCpntnmgYQ98UfFBEVq1ZU/YAGdMKBYwTK2WkZ7KtScexop7R3J8j8yQI6xiafXWvSHLi8IEksJi5YQHv2REObPNI1HZr/1lm3Yz4t/TeeyL3Gq9rqlbLGCYhJCemgzAM5dmx7kmoYX7Jb8zaCLfwcIissZN4o05P4Y8viKRjpLatMtJ274gaCZ7sNyte1jipjsxxgKGSSgn92rNZcdk+bfXjT+DVX8bxUk945s25pHPQy8Le++k0muV5x9wJgQ+OHUlAOt37OeOiUsqvH5VO70rOm34Q9M587+Vy+hrEpcFDJOwbj2tJwBpKUk8f/nguNbl5dmhWwy+AOGTJL7FnZztm95YwEuzfyh1TOD8jmDBDYzcrXt5b/6GylW2ihas38XcH3bE5LVMfFjAMAnHd1umXpgO9GO7tYhhbcoXnNzQ94Xv6zwP1Yl+1Ys5ZI2bxP2Tl5fZF2z4Q19x8xsLq13PSJz92Df86olZIfcdOFTE3B92UFSsHCqM/rBiExsWMEyd4/sV/9vju/LoBeVnxI2lkf+ZziK3v0CBGavzmP9j+D6GCdPXAs5tK1+6k2LViEY++YJqrFYIvPXthfzqiVmc8cgMevzlY7LGTeKZGWtj8tomeixgmIQTfFvHZ/qtJzFz3Mn+tOhDujanX4emsa5eWCt+2uNPn15crLy/ILJFmN6aW3LL6ZqX5zHq4RnsP1TI5MWbPalnVfg6zlcE5A579bvIOvY35x/go0VVW5DqwKEiCjyYKFlXWcAwCSfcQKFOLRrQrml9bjv9cAZ1bsaQLi1ITS75X6B90/qxqWAElMjTiQS/35Vb9nDHxKX87pWS9c2fnr6WOevi178Q6p0kRTik69wnZnH9q/PDtpw+WrSJRRtCt8QOv3MKv3piZqTVNBWwgGESloYZA9SjdQbvXHsMDeulkJJc8qWVkZ7CJUM7A5S7pGws7Pm5MKJbS4s27OJgiD6B9TtKzwi/b/JyzntyFsMf+ooJ09dUOknhs19/X7kTgoSKfZHOmdmU7wwBDjeX5fpX55e7dsmiDTYsOFosYJiEU5kvw9SAtTcGdGpKQZHzpdSnXWMuOjq+QWNiBLekznr0G578ak3E18zdupf7J6/wb+/Yd4ib31jg394bZgnaez9axm9ezGHo3z+L+LUChQrewSngK1LdjL/BLn72Wx6atqrcY2xJ3dIsYJiE06VlIwDaN21Q4bGBLYy7z+pDUbHzaz01uXbnCf8uwttPCzfk8978kpWTR/5nOht27ueZGWv5cuXWUsdOW7aFzflVW6ApVOMg0sAePHIsWmas3sYjn4WeHwMwcf5Get0xhdwws/frIktvbhLO2MEd6dKyIUd3bV7hsYF9GPVSkil0WxjJSUlRWZmvttmw8wCXPT8n6l+SoQNGZBFDREA16i2Minyy7CcAVvy0m26tGoU9rqComIKiYhqkJf7XqbUwTMIREYYe1iKiLyRfS6Jjc6fD25dVNjVZ/KOpKvK/K+I7KbAqrnghJ+y+4HQlwa57ZR73TVrGS7N/qFbywsrm/SquoYOdLn9+Dr3vnBrvasSEpwFDREaKyEoRyRWRcSH2XyYieSKywH1cFbDvUhFZ7T4u9bKepu4SEZ66eBBv/fYYAArdb6XkJOHmU3twcq9WFV8j4Pmwbi29qGZMba8gYExavJmnZ3zPHROXMMkdultRvqlQ8z0iHSUVvF56TfN1buXT1NdWngUMEUkGHgNGAb2BsSLSO8Shb6hqf/fxjHtuc+AuYAgwGLhLRJp5VVdTt53Wpw1t3IWYTuzpBIhebTJo2iCN5y47iuGHty73/MDvvZevGuJZPWuiPT87neT/+bR0X8AXK7eSNW4S+QcKUFU27y7b9xGqhbFs025mB62i6Pv3jfUtKf/rV3GNkUTkZQtjMJCrqmtV9RDwOjA6wnNPA6ap6g5V3QlMA0Z6VE9j/M4b1IHFd4+gW6uShZlO79vG//zxCwfyxIUDS50T6S/lRDRx/kZUlemr8kqV/9ftTM7duoeXZv8Quj9IhK9W5bF970F/0emPzGDMhNmlD3O/sKPd6W0qz8uA0R4IXPNxg1sW7FciskhE3haRjpU8FxG5WkRyRCQnLy8v1CHGRExEyEhPDSoreX5yr1aM6tu29P5yrvfkRQPL2Vv7fbduB3N/2MmhoNnUvsbAmq37+Hp16Fs2C9fv4tLnvmPQ3z4ts+/LlVv5fMUWp4/E/Qf29S9t2nVSmBAZAAAXwUlEQVSA7L9N4/tt+6L3RkxE4t2t/yHwmqoeFJHfAv8DTq7MBVR1AjABIDs7236CmKgLbEEEtybOPLItR3UJPxorOSnxx5XsO1R2roKvz+L/3qnasq+XuSlSAhUXK5vzDzBxwUa27T3EAx+v4OGx/at0fVM1Xv41bwQ6Bmx3cMv8VHW7qvrao88AgyI915hYCRxtlRx04/3RCwaSmpzEtScexuCssoEjOfHjhX/uik/Ouh1Utrsha9wkbn9vcbnH7D1YyNC/f84/pjhrhUxZ+hM9/zLFv/+z5VuY+8MOCsPkjlq1ZQ9Z4yYx78edlapbuIwBdZGXf85zgO4i0kVE0oAxwAeBB4hIYNv+LMCXr3kqMEJEmrmd3SPcMmNiLjBGhBsK+qeRvXjzmqEhzo28f+PFKwbTNbNhZasXd765Kz7nPjmrSv0Nr3xbfjLCitK5X/m/HH71xCzu/nApHy3aRNa4Sf59hwqL/dl9nwoxM/5/M9fR76+flCqzzu6yPAsYqloIXI/zRb8ceFNVl4rIPSJylnvYDSKyVEQWAjcAl7nn7gDuxQk6c4B73DJjYi7wSz+SuR1f/vFE/nO+c6ukb/smlXqdmpQAMVKhRi95MaBpRpi+kGAvz/6R61+dX6rszveX8Lab1Xfq0i1c+EzpjvW7PlhK/oECZqx2OuHzDxSUSQsy4J5PeP6b6uXUqu087cNQ1cnA5KCyOwOe3wbcFubc54DnvKyfMZE4rnvouRV92jUOWZ7VsiFZLRty9gBnnEbXzIaszau4gzba3R3DD2/Fp8u3VnxgNRWGiA7hbgvFy6ygobrf5JZsb9hZkqjx4me/o2WjemwLGLkFTp/Mzv0F/PXDZfTr2JSBncqO8v+5oMi/tnyiinentzE1XvCoKYAFd54a8ZfDR78fxpKNu2mQllzu+thJIhGny4hE4xD19sKM1WVHJwaPmoq35HL+XYc98EWp7eBg8a9PVrF1d0nZOY/PZPHdIygoUjLSS75Cr3hhDq/+5mgAPli4iemr8lCFf553ZKnPdfWWPbRvVj9sKpGPFm2iQVoyJ/cqf/5PPFjAMKYKmjZIi/jYBmkpDHZHUr1z7TEs37ybN3PW+9NuN05PYffPhWU61Kurflpsfu2+mVN2zfCCGrYMa1I1/m2/37aPez5aVqrs5dk/8sCUFaXKZq7ZzhcrtpY5/u/n9MW3IkhKknDqv6cDMLRrC179zRAe/TyXM45sS2ZGPV6c9QMPTnU69f95Xj+6tGxI5xYNKC5WWjVOr/J7iBYLGMbE0KDOzRjUuRkXHd2ZRRt28XXuNj5dtoV5P+4iSUrmdNxwcjeG925d7joPFYnn7ZFDRTVrZFF5LYyqCA4WPpe/UHY4cGFxMUPud9LCj+7fzl8+a+12xk9ZwVNfreVf01ZxRt+2/lQrAH98q+xa7FktGnDP6CPo3a4x17w0l5uG92BYmFumXrCAYUycHNmhKUd2aMonS531uAM71wd0akbPNhnhTo1I/SoGjP4dm7Jgffi1xCNR05ZFrU4Lo7oKCtWfQuXl2aVHgj31Vcm65pMiWFJ33fb9XPLcd/7tjxZtYkZuHtNXbePjG4+LUo3DqwOjxI2pvhevGMyVw7p4cm3fd1lykpSaVZ5SzV7w9NTIzr/rF6VTvNVLqf7XQv6BgmpfI5riOR/Gy/6cQ4XF7Nx3qMIMw9FiAcOYCBzfI5M7zgyVO7P6Hh4zgCuHdeGIdiVDcBUlSSAzox73/fKIKl030vUZmtQv3TmemoCzDeM5477Q47zshwqLSYtCkI9E4v1lGFPLdGzegDvO7E1SktC/Y1MAWjdOR0SYc/twLhzSmft/2ReALi0rntj3zrVDGTu4E2MGd6zwWKDMl020O99rgj1xbPEUFHrbn3OoKHYBw/owjKlBfn9yd0Ye0YZebUrP8bhgSCfOy+5AkggPTVtJSlISD4dZXnRQ5+YM6lzxaoM+aUEtikgXjqpN1sYxUWGB5y0MjVmr0AKGMTVIcpKUCRY+vi+FW0/rharSoVl92jerz7+nrWLOusjyIx3dtTmN6qWUmtCXGvTrNJ4dxInI6wEA1sIwxpRLRDgv27nlNLBTM3b/XMCXK/I4WMGX0+tXD+VgYVGppH3BLQxbdiK6gnNtRZMChwqLqBejFob1YRhTy6WnJtMqI51fH9WRi4/uXOHx9VKSyahX8lsx+BZUYOLAo7K8Xejy5uE9PL1+TeD1rPeCIiU1JTatQgsYxtQR1554mP95cnLAGh/lBAyvM7b+XFh2LY1Es2u/t0NeDxUWl2klesUChjF1wG+P78qfRvbyb5f3yz6Wa2cHZ4RNRFe8kOPZtYXYDqu1Pgxj6oKghsKlx2Qxun87Nu46wP6gFfO6tmzoTyUebvGg9k3rs3HXgWpX6+eCmjUjvLZRnE71WI2SshaGMXVAqFtLTRuk0addE/+edk3S+fjG4/jTqJKWSLgO8NevPtqf3v2I9qFHdUWiLrQwIHyK/OqauWYba7fts4l7xpjqu/W0ngBEknuvTZN0Dm/bmAZpKawbfwbrxp8RdnHSlGTxf0n99azSM9EvOyYr4vqd2rvmpfCOtouO7sRLVw6pVmANZ4ubdr15JbInV4fdkjImganbRCgvXpQXTHznv33NUPq0a8K2vQeZuvQn2japzxl92zL/x110aFaySmDzhmncfVYfxo3qhSpszj/Aqi17uebluSGvf3rftiHLE0WP1o3429nOLP3g20YtGqaxPQo5oK498TB+e3zXal8nEp62MERkpIisFJFcERkXYv8tIrJMRBaJyGci0jlgX5GILHAfHwSfa4ypmO+WUvktDGdnqNaEr0zEWV+jY/MGXHWc8+V05bAuLLvnNFoHrNPwyJgBgDPUt35aMl0zG3FMtxb+/ZVpfSSa4PXd2zSJzvoW15/UrVLrs1SHZwFDRJKBx4BRQG9grIgEZ2+bD2Sr6pHA28A/AvYdUNX+7uMsjDGV5v/CL6eN4fseC9VfUVJW9nwRKZPgMNTaDL4hnxcM6VQm0SHAvDtO5cPrhzG0a4sy+xKJejQjMlb9F+BtC2MwkKuqa1X1EPA6MDrwAFX9QlV9C+rOBjp4WB9j6hzfffO+HZpUcGRogS2MqkpPTWbeHadyz1l9+N1Jh9GjdaNS+5s3TKNvhyY8f/lRIc+/d3Sfqr94nAUG6uBwEa01nWKZ+8vLgNEeWB+wvcEtC+dK4OOA7XQRyRGR2SJythcVNCbRndyrNV//6SRO69OmwmND/v6NoA8kEs0bppGSnES9lGQ+ufmEkMeE++K7eGgW68afUc0axF9wAyNaDY5orgNfkRrR6S0iFwHZQOBfUmdV3SgiXYHPRWSxqq4Jce7VwNUAnTp1ikl9jalNOjRrUO7+8r5uSloY3n8pBaZVf+LCgdRLTaJhwC2v0/u2YXT/9rw9dwPTlm3xvD7R5tUtqVjysoWxEQhMyN/BLStFRIYDtwNnqepBX7mqbnT/uxb4EhgQ6kVUdYKqZqtqdmZmZvRqb0xdE+ILzd9pHoOXFxF6tcngwXOPZFTftpzcqzVDAvo1Hr9wEKf1acPjFw7kyYsG+tcOAbj82Kwy1/vHr46MQa3LFxhna3+48LaFMQfoLiJdcALFGOCCwANEZADwFDBSVbcGlDcD9qvqQRFpCRxL6Q5xY0yURNJ6iNVdjyk3HV/hManJSYw8oi0jj3CG5BYVK8lJwu2nH07e3oMM/fvnzoHl1PmhX/fjljcXAvDtn09h+95DHCws4jcv5rBtrze5nxKggeFdC0NVC4HrganAcuBNVV0qIveIiG/U04NAI+CtoOGzhwM5IrIQ+AIYr6rLvKqrMSb0L+Cz+rUDoG2T+iH21gy+W1kpyUm0CRjiGxgv7jyzNyvuHVmyL2Bn68bp9G7XmAGdmpHzl1P9kxYDHd+j9N2LwNcJ9I9zw7dqgtOs1MYA4mkfhqpOBiYHld0Z8Hx4mPNmAn29rJsxxtE43fkaOCyzUZl9Vx3XhYuHdiY9NTnW1aqScK2li47uXGr4aWWy8N579hGcN6gDs9ZsZ+WWPYz/eAV3n9WbkUe0JWvcpFLHBq7LHszLdTFipUZ0ehtj4qdrZiNevnIIgzqXXftCRGpNsAjnnIHtw85VGN2/Xdjznrkkm3Xb9/nXGDmpVytO6tWKa044LOTx7/7uGHq3a8xrvzmasU/PLrP/p90/l9qO4eCmqLFcUsYYhnVvSf20qgeG/5zfnxtO6R7FGlVfJH0z5d0WGt67tX9Wezj/PK+f//nATk7AHXpYC9659pgyxzZOdyYt3nJqSWr5l64c7H/umzPzi36lg9gH1x8b9vWfuSS73PpFm7UwjDHVdvaA8qZYxVmIoOCf3V7NS587qAN/fGthmXJfv0pg0HrlqiEs2ZhPx+YNeGjaKgCO657pTxX/6NiBZLVsyMHCIr5cuZVzBrTn5lN7hJwd/9sTutKzdQbDY5y80QKGMSYhxfOOT3KI1k3H5g3o2LwBSzbmA2VbN75cU/VSkll892mhr5skFBUrlx2TFZeBCBYwjDExN/Wm44nRmj/ltiK8mkznixeVCVqR9Gn4DgkVkGLBAoYxJuZ6tsnw/DXK+06NZTqNSEUUMHyBKE71t05vY0xCK68VUdsGuvoCRQzzDZZiAcMYk3CaN0wr9xe7b3nZSJIy1iS+txS8tkas2C0pY0xCmXTDMFplpPN1bl6ZfX3aNWbppt0cltmI1feNKrMKXrRF+3vdd72kODUxLGAYYxJKH3e2tS9Lb6+2JWtpv3PtMRwsLAbKLpkaTV6l/fDNUI/XLSkLGMaYhHRUVnM+vH6Y//YTOIs5RXvm+jvXDqVVRnSWW61IvAKF//Xj+/LGGOOdvh2aeH77ZlDn5nRsXnrNkdZN6gEw6oiK+0jOGehMegw1QS9YvEd3WQvDGGOirFVGOgvvGuFP7BioZ5sMTunVipvdFCE3D+/B707sFlFqliuGdeGRz1ZTLyU++b0sYBhjjAfCtRhSk5N49rKS9cuTkiTiPF63nNqjVC6qWLOAYYwxNdzfz+kbk8mOFbGAYYwxNdzYwZ3iXQXAOr2NMcZEyNOAISIjRWSliOSKyLgQ++uJyBvu/m9FJCtg321u+UoRCZ260RhjTMx4FjBEJBl4DBgF9AbGikjvoMOuBHaqajfg38AD7rm9gTFAH2Ak8Lh7PWOMMXHiZQtjMJCrqmtV9RDwOjA66JjRwP/c528Dp4gz0Hg08LqqHlTV74Fc93rGGGPixMuA0R5YH7C9wS0LeYyqFgL5QIsIzzXGGBNDtb7TW0SuFpEcEcnJyyubbMwYY0x0eBkwNgIdA7Y7uGUhjxGRFKAJsD3CcwFQ1Qmqmq2q2ZmZmVGqujHGmGBeBow5QHcR6SIiaTid2B8EHfMBcKn7/Fzgc3VWO/kAGOOOouoCdAe+87CuxhhjKuDZxD1VLRSR64GpQDLwnKouFZF7gBxV/QB4FnhJRHKBHThBBfe4N4FlQCFwnaoWVfSac+fO3SYiP1Sxyi2BbVU8t7ay91w32HtOfNV5v50jPVC8WgS9thGRHFXNjnc9Ysnec91g7znxxer91vpOb2OMMbFhAcMYY0xELGCUmBDvCsSBvee6wd5z4ovJ+7U+DGOMMRGxFoYxxpiI1PmAUVFG3dpKRDqKyBciskxElorIjW55cxGZJiKr3f82c8tFRB5x/x0WicjA+L6DqhORZBGZLyIfudtd3GzIuW525DS3PGy25NpERJqKyNsiskJElovI0ET/nEXkZvfveomIvCYi6Yn2OYvIcyKyVUSWBJRV+nMVkUvd41eLyKWhXitSdTpgRJhRt7YqBP6gqr2Bo4Hr3Pc2DvhMVbsDn7nb4PwbdHcfVwNPxL7KUXMjsDxg+wHg325W5J04WZIhTLbkWuhhYIqq9gL64bz3hP2cRaQ9cAOQrapH4MzzGkPifc4v4GTrDlSpz1VEmgN3AUNwErje5QsyVaKqdfYBDAWmBmzfBtwW73p59F7fB04FVgJt3bK2wEr3+VPA2IDj/cfVpgdOGpnPgJOBjwDBmdCUEvyZ40wqHeo+T3GPk3i/h0q+3ybA98H1TuTPmZLkpM3dz+0j4LRE/JyBLGBJVT9XYCzwVEB5qeMq+6jTLQzqSFZctwk+APgWaK2qm91dPwGt3eeJ8m/xH+D/gGJ3uwWwS51syFD6fYXLllybdAHygOfd23DPiEhDEvhzVtWNwD+BH4HNOJ/bXBL7c/ap7Oca1c+7rgeMhCcijYB3gJtUdXfgPnV+ciTMMDkRORPYqqpz412XGEoBBgJPqOoAYB8ltymAhPycm+GsmdMFaAc0pOytm4QXj8+1rgeMiLPi1kYikooTLF5R1Xfd4i0i0tbd3xbY6pYnwr/FscBZIrIOZ8Guk3Hu7zd1syFD6fcVLltybbIB2KCq37rbb+MEkET+nIcD36tqnqoWAO/ifPaJ/Dn7VPZzjernXdcDRiQZdWslERGc5I7LVfWhgF2BGYIvxenb8JVf4o62OBrID2j61gqqepuqdlDVLJzP8nNVvRD4AicbMpR9z6GyJdcaqvoTsF5EerpFp+Ak7UzYzxnnVtTRItLA/Tv3veeE/ZwDVPZznQqMEJFmbstshFtWNfHu1In3AzgdWAWsAW6Pd32i+L6G4TRXFwEL3MfpOPduPwNWA58Czd3jBWfE2BpgMc4IlLi/j2q8/xOBj9znXXHS4+cCbwH13PJ0dzvX3d813vWu4nvtD+S4n/VEoFmif87AX4EVwBLgJaBeon3OwGs4fTQFOC3JK6vyuQJXuO89F7i8OnWymd7GGGMiUtdvSRljjImQBQxjjDERsYBhjDEmIhYwjDHGRMQChjHGmIhYwDDGGBMRCxgm4YjITPe/WSJyQZSv/edQr+UVETlbRO6s4JgH3dTmi0TkPRFpGrDvNjfl9UoROc0tSxOR6QGzoo2JiAUMk3BU9Rj3aRZQqYARwZdoqYAR8Fpe+T/g8QqOmQYcoapH4kxCvQ3ATWc/BuiDk2vpcRFJVtVDOJO/zves1iYhWcAwCUdE9rpPxwPHicgCd8GdZPfX+Bz31/hv3eNPFJEZIvIBTooJRGSiiMx1F+m52i0bD9R3r/dK4Gu5KRkeFGdBn8Uicn7Atb+UkgWOXnHTWSAi48VZ4GqRiPwzxPvoARxU1W3u9vsicon7/Le+OqjqJ1qSpXU2Tr4gcBL0va6qB1X1e5yZvoPdfROBC6Pwz23qEGuSmkQ2Dvijqp4J4H7x56vqUSJSD/hGRD5xjx2I8yv9e3f7ClXdISL1gTki8o6qjhOR61W1f4jXOgcnRUc/oKV7znR33wCcX/mbgG+AY0VkOfBLoJeqauBtpADHAvMCtq926/w98AechbGCXQG84T5vjxNAfAJTWy8BjgpxvjFhWQvD1CUjcBK0LcBZG6QFzgplAN8FBAuAG0RkIc4XbseA48IZBrymqkWqugX4ipIv5O9UdYOqFuPk9MrCWZPhZ+BZETkH2B/imm1x1roAwL3unThJ9v6gqjsCDxaR23FWWnylgrqiqkXAIRHJqOhYY3yshWHqEgF+r6qlsnWKyIk460gEbg/HWaVtv4h8iZPArqoOBjwvwlkVrlBEBuNkWj0XuB4nHXugAzipuAP1xUnN3S7oPVwGnAmcoiUJ4ipKbV0PJ2gZExFrYZhEtgcI/AU9FbjWXScEEekhzup0wZrgrAG9X0R6UfrWT4Hv/CAzgPPdfpJM4HiczKghibOwVRNVnQzcjHMrK9hyoFvAOYNx1m4eAPxRRLq45SNxOsfPUtXAlsoHwBgRqece291XJxFpAWxTZz0JYyJiLQyTyBYBRe6tpRdwFlPKAua5Hc95wNkhzpsCXOP2M6ykdD/ABGCRiMxTZ60Nn/dw1pFeiJNW/v9U9Sc34ISSAbwvIuk4LZ9bQhwzHfiXW9c04Gmc9NSbROQPwHMicjLwKE5rYZrbnz5bVa9R1aUi8iZOR34hcJ17KwrgJGBSmLoZE5KlNzemBhORh4EPVfXTKF/3XWCcqq6K5nVNYrNbUsbUbPcDDaJ5QXFWl5xowcJUlrUwjDHGRMRaGMYYYyJiAcMYY0xELGAYY4yJiAUMY4wxEbGAYYwxJiL/D4cekzWmszSDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you [ 1.356 -1.592  0.96  -0.922 -0.942]\n",
      "say [ 0.322 -1.147 -1.191  1.191  1.199]\n",
      "goodbye [-0.217  0.745  1.133 -1.124 -1.106]\n",
      "and [ 1.812 -0.561 -0.939  0.98   0.982]\n",
      "i [-0.211  0.748  1.141 -1.12  -1.115]\n",
      "hello [ 1.344 -1.6    0.932 -0.923 -0.918]\n",
      ". [-1.657 -1.274 -1.079  1.074  1.137]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
